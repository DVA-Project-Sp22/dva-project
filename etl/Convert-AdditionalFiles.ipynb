{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Covert Additional Files\n",
    "\n",
    "The Million Song Dataset includes various other files that are not part of the standard dataset. These files are in a range of formats such as .txt, .csv, .db, .h5 and are all lumped together even though they have different schemas. This notebook convers their format to csv and loads them into our Intermediate Data Lake in their own subdirectory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libaries & Set Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "source_bucket = 'millionsongdataset-raw'\n",
    "source_prefix = 'AdditionalFiles'\n",
    "destination_bucket = 'millionsongdataset-intermediate'\n",
    "\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist Location Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_location_columns = ['artist_id', 'artist_latitude', 'artist_longitude', 'artist_name', 'artist_location']\n",
    "\n",
    "artist_location = pd.read_csv(f's3://{source_bucket}/{source_prefix}/artist_location.txt', names = artist_location_columns, sep = \"<SEP>\", header = None, engine='python')\n",
    "\n",
    "artist_location.to_csv(f's3://{destination_bucket}/artist_location/artist_location.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracks Per Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_per_year = pd.read_csv(f's3://{source_bucket}/{source_prefix}/tracks_per_year.txt', names = ['year', 'track_id', 'artist_name', 'track_name'], sep = \"<SEP>\", header = None, engine='python')\n",
    "\n",
    "tracks_per_year.to_csv(f's3://{destination_bucket}/tracks_per_year/tracks_per_year.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_artists = pd.read_csv(f's3://{source_bucket}/{source_prefix}/unique_artists.txt', names = ['artist_id', 'artist_mbid','track_id','artist_name'], sep = \"<SEP>\", header = None, engine='python')\n",
    "\n",
    "unique_artists.to_csv(f's3://{destination_bucket}/unique_artists/unique_artists.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique MB Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mb_tags = pd.read_csv(f's3://{source_bucket}/{source_prefix}/unique_mbtags.txt', names = ['tag'], sep = \"<SEP>\", header = None, engine='python')\n",
    "\n",
    "unique_mb_tags.to_csv(f's3://{destination_bucket}/unique_mbtags/unique_mbtags.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_terms = pd.read_csv(f's3://{source_bucket}/{source_prefix}/unique_terms.txt', names = ['term'], sep = \"<SEP>\", header = None, engine='python')\n",
    "\n",
    "unique_terms.to_csv(f's3://{destination_bucket}/unique_terms/unique_terms.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tracks = pd.read_csv(f's3://{source_bucket}/{source_prefix}/unique_tracks.txt', names = ['track_id', 'song_id', 'artist_name', 'song_title'], sep = \"<SEP>\", header = None, engine='python')\n",
    "\n",
    "unique_tracks.to_csv(f's3://{destination_bucket}/unique_tracks/unique_tracks.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(source_bucket, f'{source_prefix}/artist_similarity.db', 'artist_similarity.db')\n",
    "\n",
    "conn = sqlite3.connect('artist_similarity.db')\n",
    "\n",
    "artist_similarity = pd.read_sql_query(\"SELECT * FROM similarity\", conn)\n",
    "\n",
    "artist_similarity.to_csv(f's3://{destination_bucket}/artist_similarity/artist_similarity.csv', index = False)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "os.remove('artist_similarity.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artist Term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(source_bucket, f'{source_prefix}/artist_term.db', 'artist_term.db')\n",
    "\n",
    "conn = sqlite3.connect('artist_term.db')\n",
    "\n",
    "artist_mbtag = pd.read_sql_query(\"SELECT * FROM artist_mbtag\", conn)\n",
    "\n",
    "artist_mbtag.to_csv(f's3://{destination_bucket}/artist_mbtag/artist_mbtag.csv', index = False)\n",
    "\n",
    "artist_term = pd.read_sql_query(\"SELECT * FROM artist_term\", conn)\n",
    "\n",
    "artist_term.to_csv(f's3://{destination_bucket}/artist_term/artist_term.csv', index = False)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "os.remove('artist_term.db')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track MetaData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(source_bucket, f'{source_prefix}/track_metadata.db', 'track_metadata.db')\n",
    "\n",
    "conn = sqlite3.connect('track_metadata.db')\n",
    "\n",
    "track_metadata = pd.read_sql_query(\"SELECT * FROM songs\", conn)\n",
    "\n",
    "track_metadata.to_csv(f's3://{destination_bucket}/track_metadata/track_metadata.csv', index = False)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "os.remove('track_metadata.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file('millionsongdataset-associateddatasets', 'mxm_dataset.db', 'mxm_dataset.db')\n",
    "\n",
    "conn = sqlite3.connect('mxm_dataset.db')\n",
    "\n",
    "lyrics = pd.read_sql_query(\"SELECT * FROM lyrics\", conn)\n",
    "\n",
    "lyrics.to_csv(f's3://{destination_bucket}/lyrics/lyrics.csv', index = False)\n",
    "\n",
    "conn.close()\n",
    "\n",
    "os.remove('mxm_dataset.db')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c53e9bdfe80d3c5583b741a8a24bc6913c1a8c4f7d300128dacddd53305a040"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('cse6242-finalproject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
