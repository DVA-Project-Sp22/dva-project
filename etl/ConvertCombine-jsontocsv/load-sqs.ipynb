{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Loading SQS with Messages for Lambda Processing\n",
    "\n",
    "The Million Song Dataset comes with a set of files that contain the data in the .h5 format. This isn't a format we're used to working with and doesn't work well with many of the tools we use. Ideally we'd prefer the data in csv, json or parquet format.\n",
    "\n",
    "So in order to accomplish that we've built a serverless function that will take data from one S3 bucket that's in .h5 format and combine the files and convert them to csv format. The way we initiate that function is through an SQS queue. The benefit of this is that the load processes can co-currently and asyrchronously process the data.\n",
    "\n",
    "This notebook reviews the files in the first S3 bucket and then parses their names/key values and then batches in them in SQS messages 2,000 records at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We are loading the required libraries and using boto3 and the s3 client to create a list of all the files in our input bucket for use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "bucket = 'echonest-intermediate-json'\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "pages = paginator.paginate(Bucket=bucket)\n",
    "\n",
    "files = [obj['Key'] for page in pages for obj in page['Contents']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up the files for processing\n",
    "\n",
    "We only want to process files that are the .h5 extension anything else is outside the scope of this function. We also want to avoid anything in the AdditionalFiles directory because those files have a different schema than the files in the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = [f for f in files if f.endswith('.json') and not f.startswith(\"zip\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slice the List\n",
    "\n",
    "We have a million files we have to process. We can turn that list into a list of slices - each 2,000 files long. Then later we can just iterate through these slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_size = 2000\n",
    "\n",
    "slices_files = [json_files[i:i+group_size] for i in range(0, len(json_files), group_size)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queue the Messages\n",
    "\n",
    "Now we'll iterate through each slice and create a SQS message with the 2,000 associated files and some other information such as the bucket and final file name we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the service resource\n",
    "sqs = boto3.resource('sqs')\n",
    "\n",
    "# Get the queue\n",
    "queue = sqs.get_queue_by_name(QueueName = 'msd-jsontocsv')\n",
    "\n",
    "for i, slice in enumerate(slices_files):\n",
    "    message_body = {'bucket': bucket, 'files': slice, 'fileName': f'data{i}.csv'}\n",
    "\n",
    "    # Create a new message\n",
    "    response = queue.send_message(MessageBody = json.dumps(message_body))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c53e9bdfe80d3c5583b741a8a24bc6913c1a8c4f7d300128dacddd53305a040"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('cse6242-finalproject')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
